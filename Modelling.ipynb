{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\n3rDx\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\n3rDx\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from pactools.grid_search import GridSearchCVProgressBar\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classification models\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 'clean_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train)\n",
    "df.drop(labels='Unnamed: 0',axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['year', 'month', 'day', 'Latitude', 'Longitude', 'Tavg',\n",
    "       'DewPoint', 'WetBulb', 'PrecipTotal', 'ResultSpeed', 'ResultDir',\n",
    "       'AvgSpeed', 'Code', 'Species_CULEX PIPIENS',\n",
    "       'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS',\n",
    "       'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS',\n",
    "       'Species_CULEX TERRITANS', 'Species_UNSPECIFIED CULEX',\n",
    "       'day_of_week_Mon', 'day_of_week_Thu', 'day_of_week_Tue',\n",
    "       'day_of_week_Wed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=27,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.947554\n",
       "1.0    0.052446\n",
       "Name: WnvPresent, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_summary(X_train, X_test, y_train, y_test, model_name, model, model_params, problem = 'classification'):\n",
    "    '''\n",
    "    Arguments:\n",
    "    X_train, X_test, y_train, y_test : vectorized train test split of X and y\n",
    "    model_name : str name of model\n",
    "    model : model constructor\n",
    "        example: 'LogisticRegression' : LogisticRegression()\n",
    "    model_params : dictionary of param_grids for GridSearch\n",
    "        example: 'LogisticRegression' : {\n",
    "                      'penalty' : ['l1', 'l2'],\n",
    "                      'C' : [.1, 1, 10] }\n",
    "    problem : str of problem type: 'classification' or 'regression'\n",
    "    \n",
    "    Return:\n",
    "    summary_df : a single row DataFrame containing the GridSearch model and its \n",
    "              best model, predictions, and scores.\n",
    "    '''   \n",
    "    problem = problem.lower()\n",
    "    \n",
    "    if problem != 'regression' and problem != 'classification':\n",
    "        print('Invalid problem type. Try \"regression\" or \"classification\"')\n",
    "        return\n",
    "\n",
    "    summary = {}\n",
    "\n",
    "    # Track progress\n",
    "    print(f'Fitting {model_name}')\n",
    "\n",
    "    # GridSearch\n",
    "    gs = GridSearchCVProgressBar(model, model_params, cv = 5)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = gs.best_estimator_.predict(X_train)\n",
    "    y_test_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "    # Build summary\n",
    "    summary['Model Name'] = model_name\n",
    "    summary['Train Pred'] = y_train_pred\n",
    "    summary['Test Pred'] = y_test_pred\n",
    "    summary['Best Score'] = gs.best_score_\n",
    "    summary['Best Params'] = gs.best_params_\n",
    "    summary['Best Estimator'] = gs.best_estimator_\n",
    "    summary['Grid Search Model'] = gs\n",
    "\n",
    "    if problem == 'regression':\n",
    "        summary['Train Score'] = r2_score(y_train, y_train_pred)\n",
    "        summary['Test Score'] = r2_score(y_test, y_test_pred)\n",
    "    elif problem == 'classification':\n",
    "        summary['Train Score'] = accuracy_score(y_train, y_train_pred)\n",
    "        summary['Test Score'] = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Construct output dataframe \n",
    "    summary_df = pd.DataFrame([summary])\n",
    "\n",
    "    # Rearrange columns\n",
    "    summary_df = summary_df[['Model Name', 'Best Params', 'Best Score', 'Best Estimator',\n",
    "                             'Train Score', 'Test Score', 'Train Pred', 'Test Pred', 'Grid Search Model']]\n",
    "        \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_models = {\n",
    "    'LogisticRegression' : LogisticRegression(random_state = 42),\n",
    "    'KNN': KNeighborsClassifier(), \n",
    "    'NaiveBayes' : MultinomialNB(),\n",
    "    'DecisionTree' : DecisionTreeClassifier(random_state = 42), \n",
    "    'BaggedDecisionTree' : BaggingClassifier(random_state = 42),\n",
    "    'RandomForest' : RandomForestClassifier(random_state = 42), \n",
    "    'ExtraTrees' : ExtraTreesClassifier(random_state = 42), \n",
    "    'AdaBoost' : AdaBoostClassifier(random_state=42), \n",
    "    'GradientBoosting' : GradientBoostingClassifier(random_state = 42),\n",
    "    'SVM' : SVC(random_state=42),\n",
    "    'XGBoost' : XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_params = {\n",
    "    'LogisticRegression' : {\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : np.arange(.05, 1, .05) },\n",
    "    'KNN' : {\n",
    "        'n_neighbors' : np.arange(3, 22, 2) },\n",
    "    'NaiveBayes' : {\n",
    "        'alpha' : np.arange(.05, 2, .05)},\n",
    "    'DecisionTree': {\n",
    "        'max_depth' : [None, 6, 10, 14], \n",
    "        'min_samples_leaf' : [1, 2],\n",
    "        'min_samples_split': [2, 3] },\n",
    "    'BaggedDecisionTree' : {\n",
    "        'n_estimators' : [20, 60, 100] },\n",
    "    'RandomForest' : {\n",
    "        'n_estimators' : [20, 60, 100],\n",
    "        'max_depth' : [None, 2, 6, 10],\n",
    "        'min_samples_split' : [2, 3, 4] },\n",
    "    'ExtraTrees' : {\n",
    "        'n_estimators' : [20, 60, 100],\n",
    "        'max_depth' : [None, 6, 10, 14],\n",
    "        'min_samples_leaf' : [1, 2], \n",
    "        'min_samples_split' : [2, 3], },\n",
    "    'AdaBoost' : {\n",
    "        'n_estimators' : np.arange(100, 151, 25),\n",
    "        'learning_rate' : np.linspace(0.05, 1, 20) },\n",
    "    'GradientBoosting' : {\n",
    "        'n_estimators' : np.arange(5, 150, 10),\n",
    "        'learning_rate' : np.linspace(0.05, 1, 20),\n",
    "        'max_depth' : [1, 2, 3] },\n",
    "    'SVM' : {\n",
    "        'C' : np.arange(0.05, 1, .05),\n",
    "        'kernel' : ['rbf', 'linear'] },\n",
    "    'XGBoost' : {\n",
    "        'n_estimators'  : np.arange(100, 151, 25), \n",
    "        'learning_rate' : np.arange(0.1, 1, .3),\n",
    "        'max_depth' : [3],\n",
    "        'alpha' : np.arange(0, 1, .3),\n",
    "        'lambda' : np.arange(0, 1, .3),\n",
    "        'gamma' : np.arange(0, 1, .3),\n",
    "        'subsample' : [.5],\n",
    "        'n_jobs' : [4],\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
